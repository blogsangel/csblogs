---
title: Clustering
format:
  html:
    code-fold: true
jupyter: python3
---

# Clustering
Clustering in Unservised learning Solution. where we have some data and we want to group them accrding to postion and method we use for clustering.

```{python}
import time
import warnings
from itertools import cycle, islice

import matplotlib.pyplot as plt
import numpy as np

from sklearn import cluster, datasets, mixture
from sklearn.neighbors import kneighbors_graph
from sklearn.preprocessing import StandardScaler
```

Generate datasets. We choose the size big enough to see the scalability
of the algorithms, but not too big to avoid too long running times

```{python}
n_samples = 1000


# Anisotropicly distributed data
random_state = 170
X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)
transformation = [[0.6, -0.6], [-0.4, 0.8]]
X_aniso = np.dot(X, transformation)
aniso = (X_aniso, y)

# blobs with varied variances
varied = datasets.make_blobs(
    n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=random_state
)
```

Set up cluster parameters

```{python}
default_base = {
    "quantile": 0.3,"eps": 0.3,"damping": 0.9,
    "preference": -200,
    "n_neighbors": 3,
    "n_clusters": 2,
    "min_samples": 7,
    "xi": 0.05,
    "min_cluster_size": 0.1,
    "allow_single_cluster": True,
    "hdbscan_min_cluster_size": 15,
    "hdbscan_min_samples": 3,
    "random_state": 42,
}
```

We have make a noisy circle data set for show the two cluster method on that. 

```{python}
noisy_circles = datasets.make_circles(
    n_samples=n_samples, factor=0.5, noise=0.05
)
datasets = [
    (
        noisy_circles,
        {
            "damping": 0.77,
            "preference": -240,
            "quantile": 0.2,
            "n_clusters": 2,
            "min_samples": 7,
            "xi": 0.08,
        },
    )

]
```

```{python}
i_dataset, (dataset, algo_params)=0,datasets[0]
# update parameters with dataset-specific values
params = default_base.copy()
params.update(algo_params)

X, y = dataset

# normalize dataset for easier parameter selection
X = StandardScaler().fit_transform(X)

# estimate bandwidth for mean shift
bandwidth = cluster.estimate_bandwidth(X, quantile=params["quantile"])

# connectivity matrix for structured Ward
connectivity = kneighbors_graph(
    X, n_neighbors=params["n_neighbors"], include_self=False
)
# make connectivity symmetric
connectivity = 0.5 * (connectivity + connectivity.T)

```

Create cluster objects

```{python}
kmeans = cluster.KMeans(
    n_clusters=params["n_clusters"],
    n_init="auto",
    random_state=params["random_state"],
)
dbscan = cluster.DBSCAN(eps=params["eps"])


clustering_algorithms = (
    ("KMeans", kmeans),
    ("DBSCAN", dbscan),
)
```

We apply KMeans Clustering and Dbscan method and show how it works on our data

```{python}
plt.figure(figsize=(7, 3))
plt.subplots_adjust(
    left=0.02, right=0.98, bottom=0.001, top=0.95, wspace=0.05, hspace=0.01
)
plot_num=1
for name, algorithm in clustering_algorithms:
    t0 = time.time()

    # catch warnings related to kneighbors_graph
    algorithm.fit(X)

    t1 = time.time()
    if hasattr(algorithm, "labels_"):
        y_pred = algorithm.labels_.astype(int)
    else:
        y_pred = algorithm.predict(X)

    plt.subplot(len(datasets), len(clustering_algorithms), plot_num)
    if i_dataset == 0:
        plt.title(name, size=18)

    colors = np.array(list(islice(cycle(["#377eb8","#ff7f00","#4daf4a","#f781bf","#a65628","#984ea3","#999999","#e41a1c","#dede00",]),int(max(y_pred) + 1),)))
    # add black color for outliers (if any)
    colors = np.append(colors, ["#000000"])
    plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])

    plt.xlim(-2.5, 2.5)
    plt.ylim(-2.5, 2.5)
    plt.xticks(())
    plt.yticks(())
    plt.text(0.99,0.01,("%.2fs" % (t1 - t0)).lstrip("0"),
        transform=plt.gca().transAxes,
        size=15,horizontalalignment="right",
    )
    plot_num += 1

plt.show()
```

Kemans The Kmeas works to select the centeroid and select the N nearest cluster to the centroid each time so it have divided the circle into two groups

DBScan: the Db Scan work on Density based it increase the cluster area based on density increase

# References 

[1] https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html

[2] https://www.geeksforgeeks.org/dbscan-clustering-in-ml-density-based-clustering/

[3] https://www.geeksforgeeks.org/k-means-clustering-introduction/

