{
  "hash": "5cc37f5dd9bc2036e8475600ae2d54d8",
  "result": {
    "markdown": "---\ntitle: Classification\nformat:\n  html:\n    code-fold: true\n---\n\n# Classification\nIn Classification we have Multi class Data and we want to classify the Data points class.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.datasets import load_iris\nfrom sklearn import tree\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\nimport warnings\nfrom sklearn.exceptions import UndefinedMetricWarning\n```\n:::\n\n\nDefine Dataset\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\niris = load_iris()\nX, y = iris.data, iris.target\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndata = iris.data\ntarget = iris.target\nfeature_names = iris.feature_names\ntarget_names = iris.target_names\n\niris_df = pd.DataFrame(data, columns=feature_names)\niris_df['Target'] = target_names[target]\n\nplt.figure()\n# Plot each feature against the target variable\nsns.pairplot(iris_df, hue='Target', markers=[\"o\", \"s\", \"D\"])\nplt.suptitle(\"Pairplot of Iris Features by Target\", y=1.02)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n```\n<Figure size 672x480 with 0 Axes>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-2.png){width=1068 height=980}\n:::\n:::\n\n\nLoading the Iris dataset here and split the data into training and testing sets\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Load the Iris dataset\niris = load_iris()\nX, y = iris.data, iris.target\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndef DrawPricisionRecallF1Scor(y_test, y_pred,target_names):\n    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning, module='sklearn.metrics')\n    # Calculate the classification report\n    report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n    # Extract relevant metrics for each class\n    classes = list(iris.target_names)\n    precision = [report[c]['precision'] for c in classes]\n    recall = [report[c]['recall'] for c in classes]\n    f1_score = [report[c]['f1-score'] for c in classes]\n    \n    # Plotting the metrics on a histogram\n    fig, ax = plt.subplots(figsize=(10, 6))\n    bar_width = 0.2\n    index = np.arange(len(classes))\n    \n    bar1 = ax.bar(index, precision, bar_width, label='Precision')\n    bar2 = ax.bar(index + bar_width, recall, bar_width, label='Recall')\n    bar3 = ax.bar(index + 2 * bar_width, f1_score, bar_width, label='F1-Score')\n    \n    ax.set_xlabel('Classes')\n    ax.set_ylabel('Scores')\n    ax.set_title('Classification Report Metrics by Class')\n    ax.set_xticks(index + bar_width)\n    ax.set_xticklabels(classes)\n    ax.legend()\n    \n    plt.show()\n```\n:::\n\n\nTrain and Plot the Precision Recall,F1 Score for the maxdepth 1\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Train a classifier (Random Forest in this example)\nclf = DecisionTreeClassifier(max_depth=1)\n#clf = RandomForestClassifier(random_state=42)\nclf.fit(X_train, y_train)\n# Make predictions on the test set\nprint(f\"Accuracy is {clf.score(X_test,y_test):.2}%\")\ny_pred = clf.predict(X_test)\nDrawPricisionRecallF1Scor(y_test, y_pred,iris.target_names)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy is 0.63%\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-2.png){width=812 height=523}\n:::\n:::\n\n\nTrain and Plot the Precision Recall,F1 Score for the maxdepth 2\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# Train a classifier (Random Forest in this example)\nclf = DecisionTreeClassifier(max_depth=2)\n#clf = RandomForestClassifier(random_state=42)\nclf.fit(X_train, y_train)\n# Make predictions on the test set\nprint(f\"Accuracy is {clf.score(X_test,y_test):.2}%\")\ny_pred = clf.predict(X_test)\nDrawPricisionRecallF1Scor(y_test, y_pred,iris.target_names)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy is 0.97%\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-2.png){width=812 height=523}\n:::\n:::\n\n\nTrain and Plot the Precision Recall, F1 Score for the maxdepth 3\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# Train a classifier (Random Forest in this example)\nclf = DecisionTreeClassifier(max_depth=3)\n#clf = RandomForestClassifier(random_state=42)\nclf.fit(X_train, y_train)\n# Make predictions on the test set\nprint(f\"Accuracy is {clf.score(X_test,y_test):.2}%\")\ny_pred = clf.predict(X_test)\nDrawPricisionRecallF1Scor(y_test, y_pred,iris.target_names)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy is 1.0%\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-9-output-2.png){width=812 height=523}\n:::\n:::\n\n\nIn this article we have train the decision tree classifier on iris Dataset with different depth levels. and as per results it show \n\n63% accuracy with maxdepth=1\n\n96% accuracy with maxdepth=2\n\n100% accuracy with maxdepth=3\n\n\n# Reference links:\n\n[1] https://seaborn.pydata.org/generated/seaborn.pairplot.html\n\n[2] https://scikit-learn.org/stable/modules/tree.html#classification\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}